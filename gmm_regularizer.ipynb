{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gmm_regularizer.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNDpbJCMbC/jZjayhnuKnJT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8lJcWmF6EZGB","colab_type":"code","outputId":"40991e7e-d15e-41ec-8a05-6be11b568f6d","executionInfo":{"status":"ok","timestamp":1581529071776,"user_tz":360,"elapsed":13654,"user":{"displayName":"Ege Beyazıt","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDqLV_4GuV8zQApBx0FQZnBwgtdNoIo9u8C9JCluw=s64","userId":"02753041663080474765"}},"colab":{"base_uri":"https://localhost:8080/","height":672}},"source":["%tensorflow_version 1.x\n","!pip install comet_ml\n","!pip install imageio\n","from comet_ml import Experiment\n","import imageio\n","import numpy as np\n","import tensorflow as tf\n","from keras.datasets import mnist\n","from tensorflow.contrib.layers import conv2d, conv2d_transpose, layer_norm, fully_connected, l1_regularizer\n","import random\n","import os\n","import time"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting comet_ml\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/e4/53163c4e271c5a7872973135d45efb289e572c6351fa31c94cc8a98d91e1/comet_ml-3.0.3-py3-none-any.whl (178kB)\n","\r\u001b[K     |█▉                              | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n","Collecting everett[ini]>=1.0.1; python_version >= \"3.0\"\n","  Downloading https://files.pythonhosted.org/packages/12/34/de70a3d913411e40ce84966f085b5da0c6df741e28c86721114dd290aaa0/everett-1.0.2-py2.py3-none-any.whl\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n","Collecting wurlitzer>=1.0.2\n","  Downloading https://files.pythonhosted.org/packages/24/5e/f3bd8443bfdf96d2f5d10097d301076a9eb55637b7864e52d2d1a4d8c72a/wurlitzer-2.0.0-py2.py3-none-any.whl\n","Collecting comet-git-pure>=0.19.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/2b/c1ca11a237e3fcbe0c1ea53134901f30f3aa657e5ea141dccaae0f46df0e/comet_git_pure-0.19.15-py3-none-any.whl (401kB)\n","\u001b[K     |████████████████████████████████| 409kB 42.8MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n","Collecting websocket-client>=0.55.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 58.3MB/s \n","\u001b[?25hCollecting netifaces>=0.10.7\n","  Downloading https://files.pythonhosted.org/packages/0c/9b/c4c7eb09189548d45939a3d3a6b3d53979c67d124459b27a094c365c347f/netifaces-0.10.9-cp36-cp36m-manylinux1_x86_64.whl\n","Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n","Collecting configobj; extra == \"ini\"\n","  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2019.11.28)\n","Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n","Building wheels for collected packages: configobj\n","  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=d941f21e809a41841ef165d27202778cd38313983fa95f8edfceed6d6c9a86d6\n","  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n","Successfully built configobj\n","Installing collected packages: configobj, everett, wurlitzer, comet-git-pure, websocket-client, netifaces, comet-ml\n","Successfully installed comet-git-pure-0.19.15 comet-ml-3.0.3 configobj-5.0.6 everett-1.0.2 netifaces-0.10.9 websocket-client-0.57.0 wurlitzer-2.0.0\n","Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.17.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (6.2.2)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eKP1qRPSEegS","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Parameters\n","zu_list = [2]\n","ZU_DIM = 2\n","lambda_list = [0.1]\n","info_lambda = 0.1\n","# hyperparameters\n","BATCH_SIZE = 128\n","IMG_DIM = (28, 28, 1)\n","Z_DIM = 74  # noise\n","ZC_DIM = 10  # c_cat\n","OUTPUT_DIM = int(np.prod(IMG_DIM))\n","LAMBDA = 10\n","ITERS = 20001\n","CRITIC_ITER = 5\n","leakyrelu_alpha = 0.1\n","LR_D = 1e-3\n","LR_G = 1e-3\n","LR_Q = 1e-3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zEuuuxdhEnzc","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Functions\n","def save_images(X, save_path):\n","    # [-1, 1] -> [0,255]\n","    X = (np.abs(127.5 * X + 127.4999)).astype('uint8')\n","\n","    n_samples = X.shape[0]\n","    rows = int(np.sqrt(n_samples))\n","    while n_samples % rows != 0:\n","        rows -= 1\n","\n","    nh, nw = rows, n_samples // rows\n","\n","    if X.ndim == 2:\n","        X = np.reshape(X, (X.shape[0], int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1]))))\n","\n","    if X.ndim == 4:\n","        h, w = X[0].shape[:2]\n","        img = np.zeros((h * nh, w * nw, 3))\n","\n","    elif X.ndim == 3:\n","        h, w = X[0].shape[:2]\n","        img = np.zeros((h * nh, w * nw))\n","\n","    for n, x in enumerate(X):\n","        j = n // nw\n","        i = n % nw\n","        img[i * w:i * w + w, j * h:j * h + h] = x\n","\n","    imageio.imwrite(save_path, img.astype('uint8'))\n","\n","def lrelu(x):\n","    return tf.nn.relu(x) - leakyrelu_alpha * tf.nn.relu(-x)\n","\n","def generator_tf(x, reuse=True):\n","    with tf.variable_scope(\"Generator\", reuse=reuse):\n","        x = tf.identity(x, name=\"input\")\n","        x = tf.layers.dense(x, 1024, activation=tf.nn.relu)\n","        x = tf.layers.dense(x, 7 * 7 * 128, activation=tf.nn.relu)\n","        x = tf.reshape(x, [-1, 7, 7, 128])\n","        x = tf.layers.conv2d_transpose(x, 64, 4, 2, padding='same', activation=tf.nn.relu)\n","        x = tf.layers.conv2d_transpose(x, 1, 4, 2, padding='same', activation=tf.nn.tanh)\n","        x = tf.identity(x, name=\"output\")\n","\n","        return x\n","\n","def d_tf(x, reuse=True):\n","    with tf.variable_scope(\"Discriminator\", reuse=reuse):\n","        x = tf.identity(x, name=\"input\")\n","        x = tf.layers.conv2d(x, 64, 4, 2, padding='same', activation=lrelu)\n","        x = tf.layers.conv2d(x, 128, 4, 2, padding='same', activation=lrelu)\n","        x = tf.contrib.layers.flatten(x)\n","        x = tf.layers.dense(x, 1024, activation=lrelu)\n","        x = tf.layers.dense(x, 1)\n","        x = tf.identity(x, name=\"output\")\n","        return x\n","\n","def q_tf(x, reuse=True):\n","    with tf.variable_scope(\"Q\", reuse=reuse):\n","        x = tf.identity(x, name=\"input\")\n","        x = tf.layers.conv2d(x, 64, 4, 2, padding='same', activation=lrelu)\n","        x = tf.layers.conv2d(x, 128, 4, 2, padding='same', activation=lrelu)\n","        x = tf.contrib.layers.flatten(x)\n","        x = tf.layers.dense(x, 1024, activation=lrelu)\n","        x = fully_connected(x, ZC_DIM + ZU_DIM, activation_fn=None)\n","        x = tf.identity(x, name=\"output\")\n","        return x\n","\n","def q_cost_tf(z, q):\n","    # categorical part\n","    z_cat = z[:, : ZC_DIM]\n","    q_cat = q[:, : ZC_DIM]\n","    lcat = tf.nn.softmax_cross_entropy_with_logits(labels=z_cat, logits=q_cat)\n","\n","    # uniform part\n","    z_uni = z[:, ZC_DIM: ZC_DIM + ZU_DIM]\n","    q_uni = q[:, ZC_DIM: ZC_DIM + ZU_DIM]\n","\n","    luni = 0.5 * tf.square(z_uni - q_uni);\n","\n","    return tf.reduce_mean(lcat) + info_lambda * tf.reduce_mean(luni);\n","  \n","def q_cost_gmm(z, q):\n","\n","\n","    # categorical part\n","    z_cat = z[:, : ZC_DIM]\n","    q_cat = q[:, : ZC_DIM]\n","    lcat = tf.nn.softmax_cross_entropy_with_logits(labels=z_cat, logits=q_cat)\n","\n","    # uniform part\n","    z_uni = z[:, ZC_DIM: ZC_DIM + ZU_DIM]\n","    q_uni = q[:, ZC_DIM: ZC_DIM + ZU_DIM]\n","\n","    luni = 0.5 * tf.square(z_uni - q_uni);\n","\n","    return tf.reduce_mean(lcat) + info_lambda * tf.reduce_mean(luni);\n","\n","\n","\n","def prepare_mnist_list(X):\n","    X = (X.astype(np.float32) - 127.5) / 127.5\n","    X = X[:, :, :, None]\n","    return list(X)\n","\n","def random_uc():\n","    idxs = np.random.randint(ZC_DIM, size=BATCH_SIZE)\n","    onehot = np.zeros((BATCH_SIZE, ZC_DIM))\n","    onehot[np.arange(BATCH_SIZE), idxs] = 1\n","    return onehot\n","\n","def random_z():\n","    rez = np.zeros([BATCH_SIZE, Z_DIM])\n","    rez[:, : ZC_DIM] = random_uc()\n","    rez[:, ZC_DIM:] = np.random.uniform(-1, 1, size=(BATCH_SIZE, Z_DIM - ZC_DIM))\n","    return rez;\n","\n","def static_uc(n_row):\n","    idxs = np.array(list(range(ZC_DIM)))\n","    onehot = np.zeros((n_row, ZC_DIM))\n","    onehot[np.arange(n_row), idxs] = 1\n","    return onehot\n","\n","def static_z(c_idx, n_row):  # c_idx = 1 -> c1, 1 to n.\n","    onehot = static_uc(n_row)\n","    cts = np.linspace(-1, 1, n_row)\n","    rez = []\n","\n","    for cls in onehot:\n","        for val in cts:\n","            current = np.zeros(Z_DIM)\n","            current[: ZC_DIM] = cls\n","            current[ZC_DIM + (c_idx - 1): ZC_DIM + c_idx] = val\n","            rez.append(current)\n","\n","    rez = np.array(rez).reshape((n_row * ZC_DIM, Z_DIM))\n","    return rez"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUvU8XBuEvxq","colab_type":"code","cellView":"form","outputId":"08d376a7-e889-4125-d57e-14aee9846fee","executionInfo":{"status":"ok","timestamp":1581529086313,"user_tz":360,"elapsed":4554,"user":{"displayName":"Ege Beyazıt","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDqLV_4GuV8zQApBx0FQZnBwgtdNoIo9u8C9JCluw=s64","userId":"02753041663080474765"}},"colab":{"base_uri":"https://localhost:8080/","height":746}},"source":["#@title Prepare\n","tf.reset_default_graph()\n","(X_train, _), (X_test, _) = mnist.load_data()\n","X_train_list = prepare_mnist_list(X_train)\n","X_test_list = prepare_mnist_list(X_test)\n","\n","# Initialize Models\n","real_data = tf.placeholder(tf.float32, (None, *IMG_DIM))\n","z_ph = tf.placeholder(tf.float32, (None, Z_DIM))\n","fake_data = generator_tf(z_ph, reuse=False)\n","d_on_real_data = d_tf(real_data, reuse=False)\n","d_on_fake_data = d_tf(fake_data)\n","q_on_fake_data = q_tf(fake_data, reuse=False)\n","\n","# wgan\n","alpha = tf.random_uniform(shape=[tf.shape(fake_data)[0], 1, 1, 1], minval=0., maxval=1.)\n","interpolates = real_data + alpha * (fake_data - real_data)\n","gradients = tf.gradients(d_tf(interpolates), [interpolates])[0]\n","slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1, 2, 3]))\n","gradient_penalty = tf.reduce_mean((slopes - 1) ** 2)\n","\n","# cost\n","q_cost = q_cost_tf(z_ph, q_on_fake_data)\n","g_cost = -tf.reduce_mean(d_on_fake_data)\n","d_cost = tf.reduce_mean(d_on_fake_data) - tf.reduce_mean(d_on_real_data) + LAMBDA * gradient_penalty\n","\n","# params\n","g_param = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Generator')\n","d_param = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Discriminator')\n","q_param = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Q')\n","\n","# optimizers\n","g_train_op = tf.train.RMSPropOptimizer(learning_rate=LR_G).minimize(g_cost, var_list=g_param)\n","d_train_op = tf.train.RMSPropOptimizer(learning_rate=LR_D).minimize(d_cost, var_list=d_param)\n","q_train_op = tf.train.RMSPropOptimizer(learning_rate=LR_Q).minimize(q_cost, var_list=q_param + g_param)\n","\n","saver = tf.train.Saver(max_to_keep=5)\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","fix_z = []\n","\n","for i in range(ZU_DIM):\n","    fix_z.append(static_z((i+1), 10))\n","\n","os.system(\"mkdir -p .\")\n","f_train_stat = open(\"./train_log.txt\", \"w\", buffering=1)\n","f_test_stat = open(\"./test_log.txt\", \"w\", buffering=1)\n","\n","os.system(\"mkdir -p \" + \" ./save\")\n","\n","for i in range(ZU_DIM):\n","    os.system(\"mkdir -p \" + \" ./figs_c\" + str(i+1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","WARNING:tensorflow:From <ipython-input-3-abf2590040d8>:36: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From <ipython-input-3-abf2590040d8>:39: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv2DTranspose` instead.\n","WARNING:tensorflow:From <ipython-input-3-abf2590040d8>:48: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv2D` instead.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","WARNING:tensorflow:From <ipython-input-3-abf2590040d8>:71: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mXQB7PRNHYM1","colab_type":"code","outputId":"f982ce47-54af-4ad4-d6d7-0890b854c53a","executionInfo":{"status":"ok","timestamp":1581529087811,"user_tz":360,"elapsed":3185,"user":{"displayName":"Ege Beyazıt","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDqLV_4GuV8zQApBx0FQZnBwgtdNoIo9u8C9JCluw=s64","userId":"02753041663080474765"}},"colab":{"base_uri":"https://localhost:8080/","height":146}},"source":["# GMM stuff\n","# mu_vector\n","# sigma_vector -> gamma_vector\n","# pi_vector\n","# initialization: https://stackoverflow.com/questions/43284047/what-is-the-default-kernel-initializer-in-tf-layers-conv2d-and-tf-layers-dense\n","    # W = sqrt(6 / (fan_in + fan_out))\n","    # Initialize the network weights so they are uniformly distributed over an interval [-W, W].\n","    # Initialize the means of the gaussians so they are spaced evenly over [-W, W].\n","    # Initialize the variances equal to the spacing between adjacent means.\n","    # Initialize all mixing proportions equal to each other.\n","# updates\n","    # To keep variances positive, model them as exp(gamma) = sigma, and gradient descent on gamma.\n","    # Data we are modeling (w) does not have a stationary distribution ->\n","    # to avoid stability problems, rate of change of weights must be tied to the rate of change of the mixture parameters.\n","    # therefore, update <w, mu, sigma, pi> simultaneously.\n","\n","W = tf.constant(np.sqrt(6.0 / (ZC_DIM + ZU_DIM + 1024))) # [-W, W] initialized, for fc layer\n","mu_vector = tf.Variable(tf.cast(tf.linspace(-W, W, ZU_DIM), tf.float32)) # evenly spaced mus\n","gamma_vector = tf.Variable(tf.cast(tf.log(tf.repeat(mu_vector[1] - mu_vector[0], ZU_DIM)), tf.float32))\n","pi_vector = tf.Variable(tf.cast(tf.ones(ZU_DIM) / float(ZU_DIM), tf.float32)) # equal to each other, sum up to 1\n","tf.initialize_all_variables().run(session=sess)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2825: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n","Instructions for updating:\n","Use `tf.global_variables_initializer` instead.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pXKvo45RHfgs","colab_type":"code","outputId":"46c353dc-1de1-4396-ce86-c44b9aae3033","executionInfo":{"status":"error","timestamp":1581529170069,"user_tz":360,"elapsed":1388,"user":{"displayName":"Ege Beyazıt","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDqLV_4GuV8zQApBx0FQZnBwgtdNoIo9u8C9JCluw=s64","userId":"02753041663080474765"}},"colab":{"base_uri":"https://localhost:8080/","height":376}},"source":["var = [v for v in tf.trainable_variables()]\n","fc_weights = tf.trainable_variables()[-2]\n","fc_biases = tf.trainable_variables()[-1]\n","fc_weights_vals = sess.run(fc_weights)\n","fc_biases_vals = sess.run(fc_biases)\n","\n","\n","def p_j(j, w):\n","  var_j = tf.cast(tf.exp(gamma_vector[j]), tf.float32)\n","  mu_j = tf.cast(mu_vector[j], tf.float32)\n","  p1 = 1.0 / tf.math.sqrt(2.0 * np.pi * var_j)\n","  p2 = tf.exp( -tf.math.square(w - mu_j) / (2.0 * var_j) )\n","  return p1 * p2\n","\n","\n","def p_mix(w):\n","  result = 0\n","  for j in range(ZU_DIM): result += pi_vector[j] * p_j(j, w)\n","  return result\n","\n","\n","def regularizer(w):  \n","  return -tf.reduce_sum(tf.log(p_mix(w)))\n","\n","\n","def r_j(j, w): # responsibility\n","  return (pi_vector[j] * p_j(j, w)) / p_mix(w)\n","  \n","\n","def d_gamma_j(j, w): # this needs to be calculated over gamma, figure out what this becomes w/ gamma\n","  mu_j = tf.cast(mu_vector[j], tf.float32)\n","  result = tf.cast(tf.exp(gamma_vector[j]), tf.float32) * 0.5 * r_j(j, w) * tf.square(w - mu_j)\n","  return -tf.reduce_sum(result)\n","\n"," \n","def d_mu_j(j, w):\n","  mu_j = tf.cast(mu_vector[j], tf.float32)\n","  var_j = tf.cast(tf.exp(gamma_vector[j]), tf.float32)  \n","  return tf.reduce_sum(r_j(j, w) * (mu_j - w) / var_j)\n","\n","\n","def d_pi_j(j, w):\n","  return tf.reduce_sum(1.0 - (r_j(j, w) / pi_vector[j]))\n","\n","\n","def update_regularizer(lr, w):\n","  mu_list = []\n","  gamma_list = []\n","  pi_list = []\n","  for j in range(ZU_DIM):\n","    mu_list.append(mu_vector[j] - lr * d_mu_j(j, w))\n","    gamma_list.append(gamma_vector[j] - lr * d_gamma_j(j, w))\n","    pi_list.append(pi_vector[j] - lr * d_pi_j(j, w))\n","\n","  return tf.stack(mu_list), tf.stack(gamma_list), tf.stack(pi_list)\n","\n","\n","# for all j, these need to be done.\n","for i in range(100):\n","  mu_vector, gamma_vector, pi_vector = sess.run(update_regularizer(0.01, fc_weights))\n","  print(mu_vector, gamma_vector, pi_vector)\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-998911501c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# for all j, these need to be done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0mmu_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_regularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1350\u001b[0m                                       target_list, run_metadata)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"4a5t31qUFiQO","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Train loop.\n","experiment = Experiment(api_key=\"plg42bGPkFkyBcCXbg7RC8xys\", project_name=\"ColabPrototypes\", workspace=\"egebeyazit93\")\n","experiment.set_name('GMM Regularizer')\n","for it in range(ITERS):\n","    start_time = time.time()\n","\n","    # wgan update\n","    for i in range(CRITIC_ITER):\n","        data = np.array(random.sample(X_train_list, BATCH_SIZE))\n","        d_cost_rez, _ = sess.run([d_cost, d_train_op], feed_dict={real_data: data, z_ph: random_z()})\n","\n","    # info update\n","    g_cost_rez, q_cost_rez, _, _ = sess.run([g_cost, q_cost, g_train_op, q_train_op], feed_dict={z_ph: random_z()})\n","    f_train_stat.write(\"%i %g %g %g\\n\" % (it, g_cost_rez, d_cost_rez, q_cost_rez))\n","\n","    if it % 100 == 0:\n","        # sample and save\n","        print(\"Training it: %i, time/it: %g, d_cost: %g\" % (it, (time.time() - start_time), d_cost_rez))\n","        for i in range(ZU_DIM):\n","            samples = sess.run([fake_data], feed_dict={z_ph: fix_z[i]})\n","            save_images(np.squeeze(samples), './figs_c%i/samples_%.6i.png' % ((i+1), it))\n","\n","        # don't log every single iteration\n","        experiment.log_metric(\"g_train_loss\", g_cost_rez, step=it)\n","        experiment.log_metric(\"d_train_loss\", d_cost_rez, step=it)\n","        experiment.log_metric(\"q_train_loss\", q_cost_rez, step=it)\n","\n","        for var in tf.global_variables():\n","            if var.name == 'Q/fully_connected/weights:0': experiment.log_histogram_3d(sess.run(var))\n","            if var.name == 'Q/fully_connected/biases:0': experiment.log_histogram_3d(sess.run(var))"],"execution_count":0,"outputs":[]}]}