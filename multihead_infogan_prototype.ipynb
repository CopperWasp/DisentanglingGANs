{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multihead_infogan_prototype.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6oHDFB0JQq-c","colab_type":"code","cellView":"both","outputId":"d925e38f-3655-43f4-822d-6ee80d013a33","executionInfo":{"status":"ok","timestamp":1578160892333,"user_tz":360,"elapsed":16447,"user":{"displayName":"Ege Beyazıt","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDqLV_4GuV8zQApBx0FQZnBwgtdNoIo9u8C9JCluw=s64","userId":"02753041663080474765"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#@title Prepare the environment and download necessary files.\n","# download needed libraries and files\n","!pip install comet_ml;\n","!wget https://raw.githubusercontent.com/egebeyazit/infogan/master/discriminator.py\n","!wget https://raw.githubusercontent.com/egebeyazit/infogan/master/generator.py\n","!wget https://raw.githubusercontent.com/egebeyazit/infogan/master/params.py\n","!wget https://raw.githubusercontent.com/egebeyazit/infogan/master/utils.py\n","\n","from comet_ml import Experiment\n","import os\n","import numpy as np\n","import itertools\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from torch.autograd import Variable\n","import torch\n","import params\n","import utils\n","\n","# reproducibility\n","torch.manual_seed(0)\n","np.random.seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# prep sample folders\n","os.makedirs(\"./images/static/\", exist_ok=True)\n","os.makedirs(\"./images/generator1/\", exist_ok=True) # varied c generator 1\n","os.makedirs(\"./images/generator2/\", exist_ok=True) # varied c generator 2\n","os.makedirs(\"./images/static1/\", exist_ok=True) # static images by generator1\n","os.makedirs(\"./images/static2/\", exist_ok=True) # static images by generator1\n","\n","# use GPU if available\n","cuda = utils.cuda\n","FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n","\n","# get parameters\n","opt = params.opt\n","\n","# download the dataset\n","dataloader = utils.get_MNIST_loader()\n","\n","'''\n","Go to the google Colab console (ctrl+shift+i) :\n","\n","function ClickConnect(){console.log(\"Working\");document.querySelector(\"colab-toolbar-button#connect\").click()}setInterval(ClickConnect,60000)\n","\n","Dont exit the console until you get \"Working\" as the output in the console window. It would keep on clicking the page and prevent it from disconnecting.\n","'''"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting comet_ml\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/c6/fac88f43f2aa61a09fee4ffb769c73fe93fe7de75764246e70967d31da09/comet_ml-3.0.2-py3-none-any.whl (170kB)\n","\u001b[K     |████████████████████████████████| 174kB 5.2MB/s \n","\u001b[?25hCollecting comet-git-pure>=0.19.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/91/b191ae375380332f82aaa83a41c45844ee1809198085cd267fbcb95cce86/comet_git_pure-0.19.14-py3-none-any.whl (401kB)\n","\u001b[K     |████████████████████████████████| 409kB 74.1MB/s \n","\u001b[?25hCollecting websocket-client>=0.55.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 76.4MB/s \n","\u001b[?25hCollecting everett[ini]>=1.0.1; python_version >= \"3.0\"\n","  Downloading https://files.pythonhosted.org/packages/12/34/de70a3d913411e40ce84966f085b5da0c6df741e28c86721114dd290aaa0/everett-1.0.2-py2.py3-none-any.whl\n","Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n","Collecting netifaces>=0.10.7\n","  Downloading https://files.pythonhosted.org/packages/0c/9b/c4c7eb09189548d45939a3d3a6b3d53979c67d124459b27a094c365c347f/netifaces-0.10.9-cp36-cp36m-manylinux1_x86_64.whl\n","Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n","Collecting wurlitzer>=1.0.2\n","  Downloading https://files.pythonhosted.org/packages/24/5e/f3bd8443bfdf96d2f5d10097d301076a9eb55637b7864e52d2d1a4d8c72a/wurlitzer-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2019.11.28)\n","Collecting configobj; extra == \"ini\"\n","  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n","Building wheels for collected packages: configobj\n","  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=166c41954f532506bf7614a73eadaee3c290a7af84a6dead918e26f9e9e24ba8\n","  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n","Successfully built configobj\n","Installing collected packages: comet-git-pure, websocket-client, configobj, everett, netifaces, wurlitzer, comet-ml\n","Successfully installed comet-git-pure-0.19.14 comet-ml-3.0.2 configobj-5.0.6 everett-1.0.2 netifaces-0.10.9 websocket-client-0.57.0 wurlitzer-2.0.0\n","--2020-01-04 18:01:21--  https://raw.githubusercontent.com/egebeyazit/infogan/master/discriminator.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1404 (1.4K) [text/plain]\n","Saving to: ‘discriminator.py’\n","\n","discriminator.py    100%[===================>]   1.37K  --.-KB/s    in 0s      \n","\n","2020-01-04 18:01:21 (233 MB/s) - ‘discriminator.py’ saved [1404/1404]\n","\n","--2020-01-04 18:01:22--  https://raw.githubusercontent.com/egebeyazit/infogan/master/generator.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1185 (1.2K) [text/plain]\n","Saving to: ‘generator.py’\n","\n","generator.py        100%[===================>]   1.16K  --.-KB/s    in 0s      \n","\n","2020-01-04 18:01:22 (273 MB/s) - ‘generator.py’ saved [1185/1185]\n","\n","--2020-01-04 18:01:23--  https://raw.githubusercontent.com/egebeyazit/infogan/master/params.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1282 (1.3K) [text/plain]\n","Saving to: ‘params.py’\n","\n","params.py           100%[===================>]   1.25K  --.-KB/s    in 0s      \n","\n","2020-01-04 18:01:23 (189 MB/s) - ‘params.py’ saved [1282/1282]\n","\n","--2020-01-04 18:01:24--  https://raw.githubusercontent.com/egebeyazit/infogan/master/utils.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3920 (3.8K) [text/plain]\n","Saving to: ‘utils.py’\n","\n","utils.py            100%[===================>]   3.83K  --.-KB/s    in 0s      \n","\n","2020-01-04 18:01:24 (104 MB/s) - ‘utils.py’ saved [3920/3920]\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:01, 9728837.18it/s]                            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 0/28881 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 136875.30it/s]           \n","  0%|          | 0/1648877 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:00, 2331802.07it/s]                            \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["8192it [00:00, 51878.95it/s]            "],"name":"stderr"},{"output_type":"stream","text":["Extracting ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"E7ShMnH9VLwg","colab_type":"code","colab":{}},"source":["generator1, _, _, categorical_loss, continuous_loss = utils.init_GAN()\n","generator2, discriminator, adversarial_loss, categorical_loss, continuous_loss = utils.init_GAN()\n","\n","optimizer_G1 = torch.optim.Adam(generator1.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","optimizer_G2 = torch.optim.Adam(generator2.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","\n","optimizer_info1 = torch.optim.Adam(itertools.chain(generator1.parameters(), discriminator.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2))\n","optimizer_info2 = torch.optim.Adam(itertools.chain(generator2.parameters(), discriminator.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2))\n","\n","static_z, static_label, static_code = utils.get_static_gen_input()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMHD8AydQZjV","colab_type":"code","outputId":"9a6607d0-4610-4a46-a163-d18aa2929e7d","executionInfo":{"status":"error","timestamp":1578175401311,"user_tz":360,"elapsed":14483162,"user":{"displayName":"Ege Beyazıt","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDqLV_4GuV8zQApBx0FQZnBwgtdNoIo9u8C9JCluw=s64","userId":"02753041663080474765"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["experiment = Experiment(api_key=\"plg42bGPkFkyBcCXbg7RC8xys\", project_name=\"bn-infogan\", workspace=\"egebeyazit93\")\n","experiment.log_parameters(vars(opt))\n","#  Training\n","for epoch in range(opt.n_epochs):\n","    for i, (imgs, labels) in enumerate(dataloader):\n","        batch_size = imgs.shape[0]\n","\n","        # Adversarial ground truths\n","        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n","        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n","        # Configure input\n","        real_imgs = Variable(imgs.type(FloatTensor))\n","        labels = utils.to_categorical(labels.numpy(), num_columns=opt.n_classes)\n","\n","        # -----------------\n","        #  Train Generator 1\n","        # -----------------\n","        optimizer_G1.zero_grad()\n","        # Sample noise and labels as generator input\n","        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n","        label_input = utils.to_categorical(np.random.randint(0, opt.n_classes, batch_size), num_columns=opt.n_classes)\n","        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n","        # Generate a batch of images\n","        gen_imgs1 = generator1(z, label_input, code_input)\n","        # Loss measures generator's ability to fool the discriminator\n","        validity, _, _ = discriminator(gen_imgs1)\n","        g_loss1 = adversarial_loss(validity, valid)\n","        experiment.log_metric(\"g1_loss\", g_loss1.item(), step=(epoch + 1) * i)\n","        g_loss1.backward()\n","        optimizer_G1.step()\n","\n","        # -----------------\n","        #  Train Generator 2\n","        # -----------------\n","        optimizer_G2.zero_grad()\n","        # Sample noise and labels as generator input\n","        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n","        label_input = utils.to_categorical(np.random.randint(0, opt.n_classes, batch_size), num_columns=opt.n_classes)\n","        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n","        # Generate a batch of images\n","        gen_imgs2 = generator2(z, label_input, code_input)\n","        # Loss measures generator's ability to fool the discriminator\n","        validity, _, _ = discriminator(gen_imgs2)\n","        g_loss2 = adversarial_loss(validity, valid)\n","        experiment.log_metric(\"g2_loss\", g_loss2.item(), step=(epoch + 1) * i)\n","        g_loss2.backward()\n","        optimizer_G2.step()\n","\n","\n","        # ---------------------\n","        #  Train Discriminator\n","        # ---------------------\n","        optimizer_D.zero_grad()\n","        # Loss for real images\n","        real_pred, _, _ = discriminator(real_imgs)\n","        d_real_loss = adversarial_loss(real_pred, valid)\n","\n","        # Loss for fake images\n","        fake_pred, _, _ = discriminator(gen_imgs1.detach())\n","        d_fake_loss1 = adversarial_loss(fake_pred, fake)\n","        fake_pred, _, _ = discriminator(gen_imgs2.detach())\n","        d_fake_loss2 = adversarial_loss(fake_pred, fake)\n","        d_fake_loss = (d_fake_loss1 + d_fake_loss2) / 2\n","\n","        # Total discriminator loss\n","        d_loss = (d_real_loss + d_fake_loss) / 2\n","        experiment.log_metric(\"d_loss\", d_loss.item(), step=(epoch + 1) * i)\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        # ------------------\n","        # Information Loss\n","        # ------------------\n","        # Sample labels\n","        sampled_labels = np.random.randint(0, opt.n_classes, batch_size)\n","        # Ground truth labels\n","        gt_labels = Variable(LongTensor(sampled_labels), requires_grad=False)\n","        # Sample noise, labels and code as generator input\n","        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n","        label_input = utils.to_categorical(sampled_labels, num_columns=opt.n_classes)\n","        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n","\n","        # Information Loss 1\n","        optimizer_info1.zero_grad()\n","        gen_imgs1 = generator1(z, label_input, code_input)\n","        _, pred_label1, pred_code1 = discriminator(gen_imgs1)\n","        info_loss1 = params.lambda_cat * categorical_loss(pred_label1, gt_labels) + params.lambda_con * continuous_loss(pred_code1, code_input)\n","        \n","\n","        # Information Loss 2\n","        optimizer_info2.zero_grad()\n","        gen_imgs2 = generator2(z, label_input, code_input)\n","        _, pred_label2, pred_code2 = discriminator(gen_imgs2)\n","        info_loss2 = params.lambda_cat * categorical_loss(pred_label2, gt_labels) + params.lambda_con * continuous_loss(pred_code2, code_input)\n","        \n","                              \n","        info_loss1_1 = info_loss1 #- info_loss2\n","        info_loss2_2 = info_loss2 #- info_loss1\n","\n","        experiment.log_metric(\"info_loss1\", info_loss1_1.item(), step=(epoch + 1) * i)\n","        experiment.log_metric(\"info_loss2\", info_loss2_2.item(), step=(epoch + 1) * i)\n","\n","        info_loss1_1.backward(retain_graph=True)\n","        info_loss2_2.backward()\n","        \n","        optimizer_info1.step()\n","        optimizer_info2.step()\n","        \n","\n","        # --------------\n","        # Log Progress\n","        # --------------\n","        if i == len(dataloader) - 1:\n","            print(\n","                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G1 loss: %f] [G2 loss: %f] [info loss: %f]\"\n","                % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss1.item(), g_loss2.item(), info_loss1.item())\n","            )\n","        batches_done = epoch * len(dataloader) + i\n","        if batches_done % opt.sample_interval == 0:\n","            utils.sample_image(generator1, generator2, n_row=10, batches_done=batches_done)\n","\n","torch.save({'generator1': generator1.state_dict(),\n","            'generator2': generator2.state_dict(),\n","            'discriminator': discriminator.state_dict(),\n","            'parameters': opt}, './trained_models/model_final_{}'.format(opt.n_epochs))\n","\n","\n","experiment.log_asset('./trained_models/model_final_{}'.format(opt.n_epochs))\n","experiment.log_asset_folder('.', step=None, log_file_name=False, recursive=False)\n","experiment.log_asset_folder('./images', step=None, log_file_name=True, recursive=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["COMET INFO: Experiment is live on comet.ml https://www.comet.ml/egebeyazit93/bn-infogan/8e9a1e2fb7cd4517ad61a3ccc7a11076\n","\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"],"name":"stderr"},{"output_type":"stream","text":["[Epoch 0/200] [Batch 937/938] [D loss: 0.227171] [G1 loss: 0.260906] [G2 loss: 0.281181] [info loss: 1.469292]\n","[Epoch 1/200] [Batch 937/938] [D loss: 0.255146] [G1 loss: 0.250885] [G2 loss: 0.311090] [info loss: 1.470873]\n","[Epoch 2/200] [Batch 937/938] [D loss: 0.215086] [G1 loss: 0.277747] [G2 loss: 0.339698] [info loss: 1.493131]\n","[Epoch 3/200] [Batch 937/938] [D loss: 0.236408] [G1 loss: 0.207537] [G2 loss: 0.268218] [info loss: 1.478878]\n","[Epoch 4/200] [Batch 937/938] [D loss: 0.236159] [G1 loss: 0.321709] [G2 loss: 0.309771] [info loss: 1.472713]\n","[Epoch 5/200] [Batch 937/938] [D loss: 0.195843] [G1 loss: 0.330316] [G2 loss: 0.291886] [info loss: 1.481140]\n","[Epoch 6/200] [Batch 937/938] [D loss: 0.297802] [G1 loss: 0.281432] [G2 loss: 0.227950] [info loss: 1.510706]\n","[Epoch 7/200] [Batch 937/938] [D loss: 0.208144] [G1 loss: 0.317507] [G2 loss: 0.247291] [info loss: 1.469072]\n","[Epoch 8/200] [Batch 937/938] [D loss: 0.262268] [G1 loss: 0.342625] [G2 loss: 0.283586] [info loss: 1.502209]\n","[Epoch 9/200] [Batch 937/938] [D loss: 0.279288] [G1 loss: 0.453691] [G2 loss: 0.244269] [info loss: 1.470010]\n","[Epoch 10/200] [Batch 937/938] [D loss: 0.275421] [G1 loss: 0.315780] [G2 loss: 0.367176] [info loss: 1.473590]\n","[Epoch 11/200] [Batch 937/938] [D loss: 0.237414] [G1 loss: 0.229191] [G2 loss: 0.200947] [info loss: 1.470278]\n","[Epoch 12/200] [Batch 937/938] [D loss: 0.249575] [G1 loss: 0.333734] [G2 loss: 0.217432] [info loss: 1.467633]\n","[Epoch 13/200] [Batch 937/938] [D loss: 0.224244] [G1 loss: 0.188174] [G2 loss: 0.256734] [info loss: 1.489076]\n","[Epoch 14/200] [Batch 937/938] [D loss: 0.266847] [G1 loss: 0.420498] [G2 loss: 0.433098] [info loss: 1.469024]\n","[Epoch 15/200] [Batch 937/938] [D loss: 0.248361] [G1 loss: 0.164815] [G2 loss: 0.257064] [info loss: 1.531535]\n","[Epoch 16/200] [Batch 937/938] [D loss: 0.198293] [G1 loss: 0.286947] [G2 loss: 0.328392] [info loss: 1.470887]\n","[Epoch 17/200] [Batch 937/938] [D loss: 0.159304] [G1 loss: 0.282417] [G2 loss: 0.359673] [info loss: 1.500505]\n","[Epoch 18/200] [Batch 937/938] [D loss: 0.221632] [G1 loss: 0.255172] [G2 loss: 0.506697] [info loss: 1.470070]\n","[Epoch 19/200] [Batch 937/938] [D loss: 0.140381] [G1 loss: 0.272120] [G2 loss: 0.511669] [info loss: 1.477130]\n","[Epoch 20/200] [Batch 937/938] [D loss: 0.204146] [G1 loss: 0.438905] [G2 loss: 0.397760] [info loss: 1.465748]\n","[Epoch 21/200] [Batch 937/938] [D loss: 0.204738] [G1 loss: 0.494206] [G2 loss: 0.391692] [info loss: 1.471682]\n","[Epoch 22/200] [Batch 937/938] [D loss: 0.261599] [G1 loss: 0.292008] [G2 loss: 0.358668] [info loss: 1.471081]\n","[Epoch 23/200] [Batch 937/938] [D loss: 0.335534] [G1 loss: 0.369908] [G2 loss: 0.416790] [info loss: 1.468236]\n","[Epoch 24/200] [Batch 937/938] [D loss: 0.216089] [G1 loss: 0.338327] [G2 loss: 0.229659] [info loss: 1.469902]\n","[Epoch 25/200] [Batch 937/938] [D loss: 0.217489] [G1 loss: 0.328403] [G2 loss: 0.239019] [info loss: 1.472403]\n","[Epoch 26/200] [Batch 937/938] [D loss: 0.231313] [G1 loss: 0.549388] [G2 loss: 0.527075] [info loss: 1.465050]\n","[Epoch 27/200] [Batch 937/938] [D loss: 0.171086] [G1 loss: 0.474863] [G2 loss: 0.318534] [info loss: 1.473228]\n","[Epoch 28/200] [Batch 937/938] [D loss: 0.241334] [G1 loss: 0.519608] [G2 loss: 0.220303] [info loss: 1.471571]\n","[Epoch 29/200] [Batch 937/938] [D loss: 0.258923] [G1 loss: 0.578430] [G2 loss: 0.271273] [info loss: 1.475253]\n","[Epoch 30/200] [Batch 937/938] [D loss: 0.180183] [G1 loss: 0.224680] [G2 loss: 0.179350] [info loss: 1.498276]\n","[Epoch 31/200] [Batch 937/938] [D loss: 0.291332] [G1 loss: 0.523295] [G2 loss: 0.424190] [info loss: 1.469113]\n","[Epoch 32/200] [Batch 937/938] [D loss: 0.301244] [G1 loss: 0.386238] [G2 loss: 0.461457] [info loss: 1.477733]\n","[Epoch 33/200] [Batch 937/938] [D loss: 0.437801] [G1 loss: 0.728188] [G2 loss: 0.329778] [info loss: 1.465102]\n","[Epoch 34/200] [Batch 937/938] [D loss: 0.265735] [G1 loss: 0.409397] [G2 loss: 0.336938] [info loss: 1.467363]\n","[Epoch 35/200] [Batch 937/938] [D loss: 0.228764] [G1 loss: 0.201539] [G2 loss: 0.308244] [info loss: 1.469839]\n","[Epoch 36/200] [Batch 937/938] [D loss: 0.186321] [G1 loss: 0.447017] [G2 loss: 0.384589] [info loss: 1.480030]\n","[Epoch 37/200] [Batch 937/938] [D loss: 0.169556] [G1 loss: 0.286412] [G2 loss: 0.249961] [info loss: 1.496616]\n","[Epoch 38/200] [Batch 937/938] [D loss: 0.260025] [G1 loss: 0.073871] [G2 loss: 0.210465] [info loss: 1.468936]\n","[Epoch 39/200] [Batch 937/938] [D loss: 0.169516] [G1 loss: 0.361082] [G2 loss: 0.606923] [info loss: 1.466270]\n","[Epoch 40/200] [Batch 937/938] [D loss: 0.260076] [G1 loss: 0.316262] [G2 loss: 0.275725] [info loss: 1.464681]\n","[Epoch 41/200] [Batch 937/938] [D loss: 0.331036] [G1 loss: 0.141695] [G2 loss: 0.280780] [info loss: 1.466588]\n","[Epoch 42/200] [Batch 937/938] [D loss: 0.360703] [G1 loss: 0.391727] [G2 loss: 0.460954] [info loss: 1.466095]\n","[Epoch 43/200] [Batch 937/938] [D loss: 0.173877] [G1 loss: 0.251751] [G2 loss: 0.428511] [info loss: 1.465431]\n","[Epoch 44/200] [Batch 937/938] [D loss: 0.230153] [G1 loss: 0.187026] [G2 loss: 0.303799] [info loss: 1.468820]\n","[Epoch 45/200] [Batch 937/938] [D loss: 0.314723] [G1 loss: 0.364592] [G2 loss: 0.258015] [info loss: 1.476929]\n","[Epoch 46/200] [Batch 937/938] [D loss: 0.210030] [G1 loss: 0.636111] [G2 loss: 0.289567] [info loss: 1.471151]\n","[Epoch 47/200] [Batch 937/938] [D loss: 0.218162] [G1 loss: 0.306318] [G2 loss: 0.149659] [info loss: 1.472280]\n","[Epoch 48/200] [Batch 937/938] [D loss: 0.273565] [G1 loss: 0.396745] [G2 loss: 0.424999] [info loss: 1.484414]\n","[Epoch 49/200] [Batch 937/938] [D loss: 0.213202] [G1 loss: 0.378217] [G2 loss: 0.442507] [info loss: 1.468322]\n","[Epoch 50/200] [Batch 937/938] [D loss: 0.226091] [G1 loss: 0.310600] [G2 loss: 0.256218] [info loss: 1.492997]\n","[Epoch 51/200] [Batch 937/938] [D loss: 0.171425] [G1 loss: 0.374763] [G2 loss: 0.453813] [info loss: 1.515923]\n","[Epoch 52/200] [Batch 937/938] [D loss: 0.187615] [G1 loss: 0.231927] [G2 loss: 0.325149] [info loss: 1.497821]\n","[Epoch 53/200] [Batch 937/938] [D loss: 0.107410] [G1 loss: 0.421135] [G2 loss: 0.666272] [info loss: 1.466564]\n","[Epoch 54/200] [Batch 937/938] [D loss: 0.225565] [G1 loss: 0.547312] [G2 loss: 0.253975] [info loss: 1.499939]\n","[Epoch 55/200] [Batch 937/938] [D loss: 0.232103] [G1 loss: 0.422163] [G2 loss: 0.174369] [info loss: 1.498501]\n","[Epoch 56/200] [Batch 937/938] [D loss: 0.226611] [G1 loss: 0.412754] [G2 loss: 0.268463] [info loss: 1.465953]\n","[Epoch 57/200] [Batch 937/938] [D loss: 0.221605] [G1 loss: 0.378379] [G2 loss: 0.254511] [info loss: 1.470796]\n","[Epoch 58/200] [Batch 937/938] [D loss: 0.255331] [G1 loss: 0.535579] [G2 loss: 0.239890] [info loss: 1.465560]\n","[Epoch 59/200] [Batch 937/938] [D loss: 0.269127] [G1 loss: 0.146192] [G2 loss: 0.054346] [info loss: 1.497386]\n","[Epoch 60/200] [Batch 937/938] [D loss: 0.257784] [G1 loss: 0.303887] [G2 loss: 0.299989] [info loss: 1.464469]\n","[Epoch 61/200] [Batch 937/938] [D loss: 0.268290] [G1 loss: 0.322178] [G2 loss: 0.442898] [info loss: 1.465132]\n","[Epoch 62/200] [Batch 937/938] [D loss: 0.162600] [G1 loss: 0.244026] [G2 loss: 0.675419] [info loss: 1.476355]\n","[Epoch 63/200] [Batch 937/938] [D loss: 0.232859] [G1 loss: 0.127728] [G2 loss: 0.244537] [info loss: 1.485807]\n","[Epoch 64/200] [Batch 937/938] [D loss: 0.231150] [G1 loss: 0.139328] [G2 loss: 0.358392] [info loss: 1.465466]\n","[Epoch 65/200] [Batch 937/938] [D loss: 0.134321] [G1 loss: 0.656109] [G2 loss: 0.274932] [info loss: 1.464417]\n","[Epoch 66/200] [Batch 937/938] [D loss: 0.349318] [G1 loss: 0.408916] [G2 loss: 0.147312] [info loss: 1.491437]\n","[Epoch 67/200] [Batch 937/938] [D loss: 0.191262] [G1 loss: 0.462406] [G2 loss: 0.219304] [info loss: 1.465832]\n","[Epoch 68/200] [Batch 937/938] [D loss: 0.229371] [G1 loss: 0.269444] [G2 loss: 0.431724] [info loss: 1.468406]\n","[Epoch 69/200] [Batch 937/938] [D loss: 0.296917] [G1 loss: 0.282033] [G2 loss: 0.493248] [info loss: 1.464306]\n","[Epoch 70/200] [Batch 937/938] [D loss: 0.298432] [G1 loss: 0.291961] [G2 loss: 0.393622] [info loss: 1.467218]\n","[Epoch 71/200] [Batch 937/938] [D loss: 0.356166] [G1 loss: 0.456275] [G2 loss: 0.487395] [info loss: 1.467715]\n","[Epoch 72/200] [Batch 937/938] [D loss: 0.232720] [G1 loss: 0.370056] [G2 loss: 0.512140] [info loss: 1.469532]\n","[Epoch 73/200] [Batch 937/938] [D loss: 0.308396] [G1 loss: 0.278313] [G2 loss: 0.100344] [info loss: 1.469087]\n","[Epoch 74/200] [Batch 937/938] [D loss: 0.266635] [G1 loss: 0.146620] [G2 loss: 0.315240] [info loss: 1.477003]\n","[Epoch 75/200] [Batch 937/938] [D loss: 0.277541] [G1 loss: 0.479054] [G2 loss: 0.301002] [info loss: 1.501826]\n","[Epoch 76/200] [Batch 937/938] [D loss: 0.100509] [G1 loss: 0.660928] [G2 loss: 0.541805] [info loss: 1.466582]\n","[Epoch 77/200] [Batch 937/938] [D loss: 0.230642] [G1 loss: 0.283766] [G2 loss: 0.319085] [info loss: 1.464529]\n","[Epoch 78/200] [Batch 937/938] [D loss: 0.317828] [G1 loss: 0.561223] [G2 loss: 0.497105] [info loss: 1.481069]\n","[Epoch 79/200] [Batch 937/938] [D loss: 0.213943] [G1 loss: 0.671146] [G2 loss: 0.403057] [info loss: 1.464746]\n","[Epoch 80/200] [Batch 937/938] [D loss: 0.265140] [G1 loss: 0.319941] [G2 loss: 0.451487] [info loss: 1.464822]\n","[Epoch 81/200] [Batch 937/938] [D loss: 0.351862] [G1 loss: 0.061390] [G2 loss: 0.171960] [info loss: 1.464861]\n","[Epoch 82/200] [Batch 937/938] [D loss: 0.355972] [G1 loss: 0.707156] [G2 loss: 0.095557] [info loss: 1.464287]\n","[Epoch 83/200] [Batch 937/938] [D loss: 0.189380] [G1 loss: 0.893658] [G2 loss: 0.195974] [info loss: 1.468329]\n","[Epoch 84/200] [Batch 937/938] [D loss: 0.332959] [G1 loss: 0.393940] [G2 loss: 0.734996] [info loss: 1.466732]\n","[Epoch 85/200] [Batch 937/938] [D loss: 0.319737] [G1 loss: 0.679948] [G2 loss: 0.247547] [info loss: 1.468450]\n","[Epoch 86/200] [Batch 937/938] [D loss: 0.216838] [G1 loss: 0.400191] [G2 loss: 0.377849] [info loss: 1.465790]\n","[Epoch 87/200] [Batch 937/938] [D loss: 0.120503] [G1 loss: 0.331872] [G2 loss: 0.610686] [info loss: 1.467885]\n","[Epoch 88/200] [Batch 937/938] [D loss: 0.201708] [G1 loss: 0.279555] [G2 loss: 0.808057] [info loss: 1.465596]\n","[Epoch 89/200] [Batch 937/938] [D loss: 0.181162] [G1 loss: 0.531539] [G2 loss: 0.203321] [info loss: 1.465822]\n","[Epoch 90/200] [Batch 937/938] [D loss: 0.062780] [G1 loss: 0.677379] [G2 loss: 0.276132] [info loss: 1.500751]\n","[Epoch 91/200] [Batch 937/938] [D loss: 0.126573] [G1 loss: 0.212109] [G2 loss: 0.256177] [info loss: 1.465277]\n","[Epoch 92/200] [Batch 937/938] [D loss: 0.158262] [G1 loss: 0.798477] [G2 loss: 0.379345] [info loss: 1.466031]\n","[Epoch 93/200] [Batch 937/938] [D loss: 0.079033] [G1 loss: 0.485395] [G2 loss: 0.205465] [info loss: 1.464850]\n","[Epoch 94/200] [Batch 937/938] [D loss: 0.288759] [G1 loss: 0.495929] [G2 loss: 0.417092] [info loss: 1.466776]\n","[Epoch 95/200] [Batch 937/938] [D loss: 0.059604] [G1 loss: 0.574158] [G2 loss: 0.996282] [info loss: 1.467486]\n","[Epoch 96/200] [Batch 937/938] [D loss: 0.093770] [G1 loss: 0.356559] [G2 loss: 0.063507] [info loss: 1.464821]\n","[Epoch 97/200] [Batch 937/938] [D loss: 0.068558] [G1 loss: 0.252993] [G2 loss: 1.315166] [info loss: 1.465014]\n","[Epoch 98/200] [Batch 937/938] [D loss: 0.123388] [G1 loss: 0.645657] [G2 loss: 0.975111] [info loss: 1.508610]\n","[Epoch 99/200] [Batch 937/938] [D loss: 0.190157] [G1 loss: 0.505136] [G2 loss: 0.955713] [info loss: 1.466213]\n","[Epoch 100/200] [Batch 937/938] [D loss: 0.098021] [G1 loss: 0.264538] [G2 loss: 0.686468] [info loss: 1.464559]\n","[Epoch 101/200] [Batch 937/938] [D loss: 0.311032] [G1 loss: 0.539069] [G2 loss: 1.052048] [info loss: 1.466466]\n","[Epoch 102/200] [Batch 937/938] [D loss: 0.159041] [G1 loss: 0.812328] [G2 loss: 0.812345] [info loss: 1.467240]\n","[Epoch 103/200] [Batch 937/938] [D loss: 0.177890] [G1 loss: 0.539678] [G2 loss: 0.397901] [info loss: 1.465753]\n","[Epoch 104/200] [Batch 937/938] [D loss: 0.277495] [G1 loss: 0.775167] [G2 loss: 0.288504] [info loss: 1.486664]\n","[Epoch 105/200] [Batch 937/938] [D loss: 0.228035] [G1 loss: 1.314606] [G2 loss: 0.933123] [info loss: 1.465039]\n","[Epoch 106/200] [Batch 937/938] [D loss: 0.097728] [G1 loss: 1.199689] [G2 loss: 0.367792] [info loss: 1.469101]\n","[Epoch 107/200] [Batch 937/938] [D loss: 0.179426] [G1 loss: 0.721939] [G2 loss: 0.269638] [info loss: 1.466413]\n","[Epoch 108/200] [Batch 937/938] [D loss: 0.174951] [G1 loss: 0.249117] [G2 loss: 0.181323] [info loss: 1.465300]\n","[Epoch 109/200] [Batch 937/938] [D loss: 0.177878] [G1 loss: 0.981618] [G2 loss: 1.120432] [info loss: 1.465814]\n","[Epoch 110/200] [Batch 937/938] [D loss: 0.180263] [G1 loss: 0.629949] [G2 loss: 0.774701] [info loss: 1.464427]\n","[Epoch 111/200] [Batch 937/938] [D loss: 0.059042] [G1 loss: 1.239283] [G2 loss: 0.607970] [info loss: 1.464350]\n","[Epoch 112/200] [Batch 937/938] [D loss: 0.224199] [G1 loss: 0.571128] [G2 loss: 0.588618] [info loss: 1.466306]\n","[Epoch 113/200] [Batch 937/938] [D loss: 0.058124] [G1 loss: 1.131667] [G2 loss: 1.080298] [info loss: 1.466609]\n","[Epoch 114/200] [Batch 937/938] [D loss: 0.373094] [G1 loss: 1.298227] [G2 loss: 0.526940] [info loss: 1.465339]\n","[Epoch 115/200] [Batch 937/938] [D loss: 0.179267] [G1 loss: 0.259448] [G2 loss: 0.382392] [info loss: 1.466004]\n","[Epoch 116/200] [Batch 937/938] [D loss: 0.199836] [G1 loss: 0.547646] [G2 loss: 0.718268] [info loss: 1.495341]\n","[Epoch 117/200] [Batch 937/938] [D loss: 0.184432] [G1 loss: 0.287054] [G2 loss: 0.043057] [info loss: 1.466470]\n","[Epoch 118/200] [Batch 937/938] [D loss: 0.033954] [G1 loss: 0.669401] [G2 loss: 0.537595] [info loss: 1.466020]\n","[Epoch 119/200] [Batch 937/938] [D loss: 0.146984] [G1 loss: 0.562466] [G2 loss: 0.952164] [info loss: 1.464939]\n","[Epoch 120/200] [Batch 937/938] [D loss: 0.095466] [G1 loss: 0.904794] [G2 loss: 1.731513] [info loss: 1.466641]\n","[Epoch 121/200] [Batch 937/938] [D loss: 0.108847] [G1 loss: 1.403358] [G2 loss: 0.642073] [info loss: 1.465227]\n","[Epoch 122/200] [Batch 937/938] [D loss: 0.295258] [G1 loss: 0.621951] [G2 loss: 0.724061] [info loss: 1.464849]\n","[Epoch 123/200] [Batch 937/938] [D loss: 0.173573] [G1 loss: 1.114774] [G2 loss: 1.534169] [info loss: 1.468188]\n","[Epoch 124/200] [Batch 937/938] [D loss: 0.200859] [G1 loss: 0.897599] [G2 loss: 0.553210] [info loss: 1.496294]\n","[Epoch 125/200] [Batch 937/938] [D loss: 0.191194] [G1 loss: 1.435061] [G2 loss: 1.519519] [info loss: 1.466490]\n","[Epoch 126/200] [Batch 937/938] [D loss: 0.168494] [G1 loss: 0.820997] [G2 loss: 0.167147] [info loss: 1.466186]\n","[Epoch 127/200] [Batch 937/938] [D loss: 0.236424] [G1 loss: 0.691225] [G2 loss: 0.920114] [info loss: 1.464936]\n","[Epoch 128/200] [Batch 937/938] [D loss: 0.104133] [G1 loss: 0.602466] [G2 loss: 0.662056] [info loss: 1.467020]\n","[Epoch 129/200] [Batch 937/938] [D loss: 0.142852] [G1 loss: 1.083872] [G2 loss: 0.581641] [info loss: 1.465014]\n","[Epoch 130/200] [Batch 937/938] [D loss: 0.070032] [G1 loss: 0.531585] [G2 loss: 0.238457] [info loss: 1.464413]\n","[Epoch 131/200] [Batch 937/938] [D loss: 0.092615] [G1 loss: 0.528188] [G2 loss: 0.285187] [info loss: 1.464591]\n","[Epoch 132/200] [Batch 937/938] [D loss: 0.158668] [G1 loss: 0.533598] [G2 loss: 0.328535] [info loss: 1.466387]\n","[Epoch 133/200] [Batch 937/938] [D loss: 0.054446] [G1 loss: 0.554450] [G2 loss: 0.386087] [info loss: 1.465724]\n","[Epoch 134/200] [Batch 937/938] [D loss: 0.156377] [G1 loss: 0.327074] [G2 loss: 0.362637] [info loss: 1.470450]\n","[Epoch 135/200] [Batch 937/938] [D loss: 0.053692] [G1 loss: 0.262950] [G2 loss: 1.364248] [info loss: 1.464746]\n","[Epoch 136/200] [Batch 937/938] [D loss: 0.055540] [G1 loss: 0.713774] [G2 loss: 0.585938] [info loss: 1.470796]\n","[Epoch 137/200] [Batch 937/938] [D loss: 0.162609] [G1 loss: 0.563933] [G2 loss: 1.273554] [info loss: 1.464331]\n","[Epoch 138/200] [Batch 937/938] [D loss: 0.286671] [G1 loss: 0.811431] [G2 loss: 0.549298] [info loss: 1.465546]\n","[Epoch 139/200] [Batch 937/938] [D loss: 0.118344] [G1 loss: 0.145948] [G2 loss: 0.961400] [info loss: 1.464027]\n","[Epoch 140/200] [Batch 937/938] [D loss: 0.107207] [G1 loss: 0.030737] [G2 loss: 1.417850] [info loss: 1.463760]\n","[Epoch 141/200] [Batch 937/938] [D loss: 0.352635] [G1 loss: 0.827194] [G2 loss: 1.849693] [info loss: 1.465360]\n","[Epoch 142/200] [Batch 937/938] [D loss: 0.203542] [G1 loss: 0.136031] [G2 loss: 0.313359] [info loss: 1.464297]\n","[Epoch 143/200] [Batch 937/938] [D loss: 0.100581] [G1 loss: 0.179359] [G2 loss: 0.366548] [info loss: 1.467624]\n","[Epoch 144/200] [Batch 937/938] [D loss: 0.345537] [G1 loss: 0.130438] [G2 loss: 0.622173] [info loss: 1.465220]\n","[Epoch 145/200] [Batch 937/938] [D loss: 0.204277] [G1 loss: 0.589028] [G2 loss: 0.174094] [info loss: 1.464433]\n","[Epoch 146/200] [Batch 937/938] [D loss: 0.122521] [G1 loss: 0.802071] [G2 loss: 1.089353] [info loss: 1.486048]\n","[Epoch 147/200] [Batch 937/938] [D loss: 0.030847] [G1 loss: 0.571785] [G2 loss: 0.299945] [info loss: 1.466657]\n","[Epoch 148/200] [Batch 937/938] [D loss: 0.120695] [G1 loss: 0.159409] [G2 loss: 0.362056] [info loss: 1.466654]\n","[Epoch 149/200] [Batch 937/938] [D loss: 0.055639] [G1 loss: 1.527588] [G2 loss: 0.631182] [info loss: 1.465231]\n","[Epoch 150/200] [Batch 937/938] [D loss: 0.074091] [G1 loss: 0.719871] [G2 loss: 0.550886] [info loss: 1.464641]\n","[Epoch 151/200] [Batch 937/938] [D loss: 0.133782] [G1 loss: 0.664227] [G2 loss: 0.727991] [info loss: 1.496258]\n","[Epoch 152/200] [Batch 937/938] [D loss: 0.147163] [G1 loss: 0.336029] [G2 loss: 0.797171] [info loss: 1.464542]\n","[Epoch 153/200] [Batch 937/938] [D loss: 0.082746] [G1 loss: 0.791696] [G2 loss: 0.641047] [info loss: 1.495957]\n","[Epoch 154/200] [Batch 937/938] [D loss: 0.167098] [G1 loss: 1.554417] [G2 loss: 1.403557] [info loss: 1.466277]\n","[Epoch 155/200] [Batch 937/938] [D loss: 0.191924] [G1 loss: 0.476751] [G2 loss: 0.524700] [info loss: 1.466993]\n","[Epoch 156/200] [Batch 937/938] [D loss: 0.117800] [G1 loss: 0.049476] [G2 loss: 0.573703] [info loss: 1.464554]\n","[Epoch 157/200] [Batch 937/938] [D loss: 0.058231] [G1 loss: 0.124408] [G2 loss: 0.474286] [info loss: 1.464733]\n","[Epoch 158/200] [Batch 937/938] [D loss: 0.326089] [G1 loss: 0.389046] [G2 loss: 1.083083] [info loss: 1.464267]\n","[Epoch 159/200] [Batch 937/938] [D loss: 0.332683] [G1 loss: 2.005700] [G2 loss: 0.943667] [info loss: 1.473136]\n","[Epoch 160/200] [Batch 937/938] [D loss: 0.215942] [G1 loss: 1.274810] [G2 loss: 0.434146] [info loss: 1.470524]\n","[Epoch 161/200] [Batch 937/938] [D loss: 0.053030] [G1 loss: 0.492424] [G2 loss: 0.685522] [info loss: 1.466847]\n","[Epoch 162/200] [Batch 937/938] [D loss: 0.185708] [G1 loss: 0.596162] [G2 loss: 1.169718] [info loss: 1.463422]\n","[Epoch 163/200] [Batch 937/938] [D loss: 0.170584] [G1 loss: 0.736879] [G2 loss: 1.034909] [info loss: 1.463953]\n","[Epoch 164/200] [Batch 937/938] [D loss: 0.368762] [G1 loss: 0.609431] [G2 loss: 0.283460] [info loss: 1.487315]\n","[Epoch 165/200] [Batch 937/938] [D loss: 0.172858] [G1 loss: 1.132880] [G2 loss: 0.847033] [info loss: 1.464112]\n","[Epoch 166/200] [Batch 937/938] [D loss: 0.174018] [G1 loss: 0.823996] [G2 loss: 0.342176] [info loss: 1.463693]\n","[Epoch 167/200] [Batch 937/938] [D loss: 0.158394] [G1 loss: 0.540433] [G2 loss: 1.847056] [info loss: 1.465352]\n","[Epoch 168/200] [Batch 937/938] [D loss: 0.224937] [G1 loss: 0.118123] [G2 loss: 0.690397] [info loss: 1.477442]\n","[Epoch 169/200] [Batch 937/938] [D loss: 0.057016] [G1 loss: 0.681825] [G2 loss: 0.888971] [info loss: 1.466638]\n","[Epoch 170/200] [Batch 937/938] [D loss: 0.051715] [G1 loss: 0.657612] [G2 loss: 0.881550] [info loss: 1.464616]\n","[Epoch 171/200] [Batch 937/938] [D loss: 0.098325] [G1 loss: 0.456910] [G2 loss: 0.824828] [info loss: 1.463927]\n","[Epoch 172/200] [Batch 937/938] [D loss: 0.077312] [G1 loss: 0.682013] [G2 loss: 0.368568] [info loss: 1.465568]\n","[Epoch 173/200] [Batch 937/938] [D loss: 0.457344] [G1 loss: 1.398679] [G2 loss: 1.178414] [info loss: 1.463613]\n","[Epoch 174/200] [Batch 937/938] [D loss: 0.537552] [G1 loss: 0.488505] [G2 loss: 0.206804] [info loss: 1.464706]\n","[Epoch 175/200] [Batch 937/938] [D loss: 0.097372] [G1 loss: 0.535201] [G2 loss: 0.551169] [info loss: 1.470124]\n","[Epoch 176/200] [Batch 937/938] [D loss: 0.268640] [G1 loss: 0.447850] [G2 loss: 0.278924] [info loss: 1.465324]\n","[Epoch 177/200] [Batch 937/938] [D loss: 0.038753] [G1 loss: 0.730849] [G2 loss: 0.512280] [info loss: 1.464444]\n","[Epoch 178/200] [Batch 937/938] [D loss: 0.179470] [G1 loss: 0.329232] [G2 loss: 1.230718] [info loss: 1.465384]\n","[Epoch 179/200] [Batch 937/938] [D loss: 0.038146] [G1 loss: 0.989157] [G2 loss: 0.533248] [info loss: 1.464453]\n","[Epoch 180/200] [Batch 937/938] [D loss: 0.044151] [G1 loss: 0.760862] [G2 loss: 0.721973] [info loss: 1.478850]\n","[Epoch 181/200] [Batch 937/938] [D loss: 0.149169] [G1 loss: 0.762379] [G2 loss: 0.609096] [info loss: 1.463558]\n","[Epoch 182/200] [Batch 937/938] [D loss: 0.087250] [G1 loss: 0.747879] [G2 loss: 1.051142] [info loss: 1.463175]\n","[Epoch 183/200] [Batch 937/938] [D loss: 0.304540] [G1 loss: 0.341590] [G2 loss: 0.704761] [info loss: 1.465692]\n","[Epoch 184/200] [Batch 937/938] [D loss: 0.204043] [G1 loss: 1.278712] [G2 loss: 1.552087] [info loss: 1.466613]\n","[Epoch 185/200] [Batch 937/938] [D loss: 0.133682] [G1 loss: 0.786366] [G2 loss: 1.535854] [info loss: 1.466012]\n","[Epoch 186/200] [Batch 937/938] [D loss: 0.069124] [G1 loss: 0.825727] [G2 loss: 1.193426] [info loss: 1.465584]\n","[Epoch 187/200] [Batch 937/938] [D loss: 0.100613] [G1 loss: 0.935762] [G2 loss: 1.240089] [info loss: 1.465591]\n","[Epoch 188/200] [Batch 937/938] [D loss: 0.070438] [G1 loss: 0.816782] [G2 loss: 0.991917] [info loss: 1.464872]\n","[Epoch 189/200] [Batch 937/938] [D loss: 0.198193] [G1 loss: 0.289864] [G2 loss: 0.414564] [info loss: 1.464807]\n","[Epoch 190/200] [Batch 937/938] [D loss: 0.373136] [G1 loss: 0.905391] [G2 loss: 0.374122] [info loss: 1.463452]\n","[Epoch 191/200] [Batch 937/938] [D loss: 0.161024] [G1 loss: 0.417043] [G2 loss: 1.055389] [info loss: 1.465225]\n","[Epoch 192/200] [Batch 937/938] [D loss: 0.362772] [G1 loss: 0.312282] [G2 loss: 1.565225] [info loss: 1.464687]\n","[Epoch 193/200] [Batch 937/938] [D loss: 0.206576] [G1 loss: 0.734665] [G2 loss: 0.689025] [info loss: 1.463526]\n","[Epoch 194/200] [Batch 937/938] [D loss: 0.179055] [G1 loss: 1.018266] [G2 loss: 0.732836] [info loss: 1.464970]\n","[Epoch 195/200] [Batch 937/938] [D loss: 0.207623] [G1 loss: 0.367619] [G2 loss: 0.281295] [info loss: 1.479133]\n","[Epoch 196/200] [Batch 937/938] [D loss: 0.232818] [G1 loss: 0.032717] [G2 loss: 0.707207] [info loss: 1.464016]\n","[Epoch 197/200] [Batch 937/938] [D loss: 0.178831] [G1 loss: 0.304941] [G2 loss: 0.192349] [info loss: 1.524934]\n","[Epoch 198/200] [Batch 937/938] [D loss: 0.063531] [G1 loss: 0.412262] [G2 loss: 0.936238] [info loss: 1.474978]\n","[Epoch 199/200] [Batch 937/938] [D loss: 0.136798] [G1 loss: 0.403470] [G2 loss: 1.726216] [info loss: 1.465362]\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d0264ce82dba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;34m'generator2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerator2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;34m'discriminator'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             'parameters': opt}, './trained_models/model_final_{}'.format(opt.n_epochs))\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './trained_models/model_final_200'"]}]},{"cell_type":"code","metadata":{"id":"tVbFy6ScQvDV","colab_type":"code","outputId":"773aa471-4d53-49be-d72c-61268bb1b91c","executionInfo":{"status":"error","timestamp":1578328392626,"user_tz":360,"elapsed":1017,"user":{"displayName":"Ege Beyazıt","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDqLV_4GuV8zQApBx0FQZnBwgtdNoIo9u8C9JCluw=s64","userId":"02753041663080474765"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-eb8d9e680597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","metadata":{"id":"RAKzUZ5Bs-xn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}